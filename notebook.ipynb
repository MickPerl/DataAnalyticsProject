{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(13)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ACQUISITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_csv = [\"movies.csv\", \"ratings.csv\", \"genome-scores.csv\", \"genome-tags.csv\", \"links.csv\", \"tags.csv\"]\n",
    "datasets_name = [i[:-4].replace(\"-\", \"_\") for i in datasets_csv]\n",
    "\n",
    "root_URL = \"http://github.com/MickPerl/DataAnalyticsProject/releases/download/datasets/\"\n",
    "remote_url = [\"\".join([root_URL, i]) for i in datasets_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    if os.getcwd().split(\"/\")[-1] != 'ml-25m':\n",
    "        os.chdir('data/ml-25m/')\n",
    "except FileNotFoundError :\n",
    "    os.makedirs(\"data/ml-25m\")\n",
    "    os.chdir('data/ml-25m/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per vedere se i csv sono gi√† presenti\n",
    "!ls\n",
    "\n",
    "# per assicurarsi di essere nel virtual environment\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download in progress of genome-scores.csv\n",
      "Download in progress of genome-tags.csv\n",
      "Download in progress of links.csv\n",
      "Download in progress of tags.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(datasets_csv)):\n",
    "    try :\n",
    "        globals()[\"_\".join(['df', datasets_name[i]])] = pd.read_csv(datasets_csv[i])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Download in progress of {datasets_csv[i]}\")\n",
    "        file = urllib.request.urlretrieve(remote_url[i], datasets_csv[i])\n",
    "        globals()[\"_\".join(['df', datasets_name[i]])] = pd.read_csv(file[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies[\"year\"] = [i.strip()[-5:-1] for i in df_movies[\"title\"]]\n",
    "df_movies[\"title_length\"] = [len(i) for i in df_movies[\"title\"]]\n",
    "df_movies.drop(\"title\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPIEGARE\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_movies = df_movies.join(pd.DataFrame(\n",
    "                mlb.fit_transform(df_movies.pop('genres').str.split('|')),\n",
    "                index=df_movies.index,\n",
    "                columns=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['genres'] = df_movies.iloc[:,3:23].values.tolist()\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.bitwise_xor([1,1,0,0,0],[1,0,1,1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genome = pd.merge(df_genome_tags, df_genome_scores, on=\"tagId\")\n",
    "df_genome = df_genome.pivot(index='movieId', columns='tag', values=\"relevance\")\n",
    "df = pd.merge(df_movies, df_genome, on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = df_ratings.iloc[:,[1,2]]\n",
    "df_ratings = df_ratings.groupby(by='movieId').mean()\n",
    "df = pd.merge(df_ratings, df, on=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.loc[:,df.columns != 'rating']\n",
    "df_Y = df['rating']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_X, df_Y, test_size=0.2, random_state=20)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', df.shape[0]+1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select rows with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[pd.isnull(df).any(axis=1)])\n",
    "# df.fillna(interesting_metric)     or      df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DupChecking correlatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION\n",
    "Y_train = (Y_train - Y_train.mean()) / Y_train.std()\n",
    "Y_train.plot(kind ='density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('expand_frame_repr', False)\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE DATA VISUALIZATION\n",
    "df_.plot(kind ='density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "sns.pairplot(df, hue=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRE DATA VISUALIZATION\n",
    "df_Y.plot(kind ='density')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
